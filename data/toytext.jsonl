{"text":"While liking or upvoting a post on a mobile app is easy to do, replying with a written note is much more difficult, due to both the cognitive load of coming up with a meaningful response as "}
{"text":"well as the mechanics of entering the text. Here we present a novel textual reply generation model that goes beyond the current auto-reply and predictive text entry models by taking into account the content preferences of the user, the idiosyncrasies"}
{"text":"of their conversational style, and even the structure of their social graph. Specifically, we have developed two types of models for personalized user interactions"}
{"text":"a content-based conversation model, which makes use of location together with user information, and a social-graph- based conversation model, which combines content-based conversation models with social graphs."}
{"text":"Yik Yak is a location-based social app, where people can view text and images posted within a five- mile radius. Users talk about a variety of topics on our platform such as sports, politics, entertainment, food, etc. They voice their opinions on these topics in the form of yaks (posts), comments (replies to yaks), and upvotes and downvotes to both yaks and comments."}
{"text":"This user activity results in a flood of events that we then analyze for a variety of purposes, such as categorizing content, building user profiles, and deriving a social graph, to ultimately provide a more personalized and engaging user experience."}
{"text":"As people discuss a variety of topics on our platform, many different opinions are voiced in the form of upvotes, downvotes, and replies (see Fig. 1). However, typing a reply on a phone is not the most convenient experience, "}
{"text":" so we have started experimenting with the ability to provide highly personalized reply suggestions, with the hope that it will improve user experience and increase engagement on a per-yak basis as well as on the app overall."}
{"text":"There has also been various work on conversation models or chatbots using neural generative models such as seq2seq. We briefly describe some of the related work in this section. Chatbots, also called conversational agents or dialog systems, have been studied by a variety of researchers from both academia and industry. We briefly describe the historical work. There are two main classes of conversational models: retrieval-b"}
{"text":"retrieval based models use a repository of predefined responses and some heuristic to choose an appropriate response based on the input and the context, generative models go beyond predefined responses and are able to generate new responses from scratc"}
{"text":"the practical applications of SEQ2SEQ. Similar to other seq2seq models, the Smart reply system is built on a pair of recurrent neural networks, one used to encode the incoming email and one to predict possible responses. "}
{"text":"The encoding network ingests the words of the incoming email one at a time and produces a vector. This vector, which Geoff Hinton calls a thought vector Hinton [2016], captures the gist of what is being said while abstracting from the specific words used."}
{"text":"While these models are fairly easy to train, they have a tendency to produce generic answers for any type of topic or interaction as presented in Li et al. [2016a]. Also, they suffer from the same issues as general recurrent models, namely a vanishing gradient when the length of the sentence is too long"}
{"text":"There has been recent work that incorporates topic Xing et al. [2016] as well as context Ghosh et al. [2016] in the SEQ2SEQ models in order to generate topic-based responses. While these models do come up with responses that might belong to one domain, they raise the question of whether it is sufficient for an intelligent agent to generate a single answer per topic or contex"}
{"text":"While liking or upvoting a post on a mobile app is easy to do, replying with a written note is much more difficult, due to both the cognitive load of coming up with a meaningful response as "}
{"text":"well as the mechanics of entering the text. Here we present a novel textual reply generation model that goes beyond the current auto-reply and predictive text entry models by taking into account the content preferences of the user, the idiosyncrasies"}
{"text":"of their conversational style, and even the structure of their social graph. Specifically, we have developed two types of models for personalized user interactions"}
{"text":"a content-based conversation model, which makes use of location together with user information, and a social-graph- based conversation model, which combines content-based conversation models with social graphs."}
{"text":"Yik Yak is a location-based social app, where people can view text and images posted within a five- mile radius. Users talk about a variety of topics on our platform such as sports, politics, entertainment, food, etc. They voice their opinions on these topics in the form of yaks (posts), comments (replies to yaks), and upvotes and downvotes to both yaks and comments."}
{"text":"This user activity results in a flood of events that we then analyze for a variety of purposes, such as categorizing content, building user profiles, and deriving a social graph, to ultimately provide a more personalized and engaging user experience."}
{"text":"As people discuss a variety of topics on our platform, many different opinions are voiced in the form of upvotes, downvotes, and replies (see Fig. 1). However, typing a reply on a phone is not the most convenient experience, "}
{"text":" so we have started experimenting with the ability to provide highly personalized reply suggestions, with the hope that it will improve user experience and increase engagement on a per-yak basis as well as on the app overall."}
{"text":"There has also been various work on conversation models or chatbots using neural generative models such as seq2seq. We briefly describe some of the related work in this section. Chatbots, also called conversational agents or dialog systems, have been studied by a variety of researchers from both academia and industry. We briefly describe the historical work. There are two main classes of conversational models: retrieval-b"}
{"text":"retrieval based models use a repository of predefined responses and some heuristic to choose an appropriate response based on the input and the context, generative models go beyond predefined responses and are able to generate new responses from scratc"}
{"text":"the practical applications of SEQ2SEQ. Similar to other seq2seq models, the Smart reply system is built on a pair of recurrent neural networks, one used to encode the incoming email and one to predict possible responses. "}
{"text":"The encoding network ingests the words of the incoming email one at a time and produces a vector. This vector, which Geoff Hinton calls a thought vector Hinton [2016], captures the gist of what is being said while abstracting from the specific words used."}
{"text":"While these models are fairly easy to train, they have a tendency to produce generic answers for any type of topic or interaction as presented in Li et al. [2016a]. Also, they suffer from the same issues as general recurrent models, namely a vanishing gradient when the length of the sentence is too long"}
{"text":"There has been recent work that incorporates topic Xing et al. [2016] as well as context Ghosh et al. [2016] in the SEQ2SEQ models in order to generate topic-based responses. While these models do come up with responses that might belong to one domain, they raise the question of whether it is sufficient for an intelligent agent to generate a single answer per topic or contex"}
{"text":"While liking or upvoting a post on a mobile app is easy to do, replying with a written note is much more difficult, due to both the cognitive load of coming up with a meaningful response as "}
{"text":"well as the mechanics of entering the text. Here we present a novel textual reply generation model that goes beyond the current auto-reply and predictive text entry models by taking into account the content preferences of the user, the idiosyncrasies"}
{"text":"of their conversational style, and even the structure of their social graph. Specifically, we have developed two types of models for personalized user interactions"}
{"text":"a content-based conversation model, which makes use of location together with user information, and a social-graph- based conversation model, which combines content-based conversation models with social graphs."}
{"text":"Yik Yak is a location-based social app, where people can view text and images posted within a five- mile radius. Users talk about a variety of topics on our platform such as sports, politics, entertainment, food, etc. They voice their opinions on these topics in the form of yaks (posts), comments (replies to yaks), and upvotes and downvotes to both yaks and comments."}
{"text":"This user activity results in a flood of events that we then analyze for a variety of purposes, such as categorizing content, building user profiles, and deriving a social graph, to ultimately provide a more personalized and engaging user experience."}
{"text":"As people discuss a variety of topics on our platform, many different opinions are voiced in the form of upvotes, downvotes, and replies (see Fig. 1). However, typing a reply on a phone is not the most convenient experience, "}
{"text":" so we have started experimenting with the ability to provide highly personalized reply suggestions, with the hope that it will improve user experience and increase engagement on a per-yak basis as well as on the app overall."}
{"text":"There has also been various work on conversation models or chatbots using neural generative models such as seq2seq. We briefly describe some of the related work in this section. Chatbots, also called conversational agents or dialog systems, have been studied by a variety of researchers from both academia and industry. We briefly describe the historical work. There are two main classes of conversational models: retrieval-b"}
{"text":"retrieval based models use a repository of predefined responses and some heuristic to choose an appropriate response based on the input and the context, generative models go beyond predefined responses and are able to generate new responses from scratc"}
{"text":"the practical applications of SEQ2SEQ. Similar to other seq2seq models, the Smart reply system is built on a pair of recurrent neural networks, one used to encode the incoming email and one to predict possible responses. "}
{"text":"The encoding network ingests the words of the incoming email one at a time and produces a vector. This vector, which Geoff Hinton calls a thought vector Hinton [2016], captures the gist of what is being said while abstracting from the specific words used."}
{"text":"While these models are fairly easy to train, they have a tendency to produce generic answers for any type of topic or interaction as presented in Li et al. [2016a]. Also, they suffer from the same issues as general recurrent models, namely a vanishing gradient when the length of the sentence is too long"}
{"text":"There has been recent work that incorporates topic Xing et al. [2016] as well as context Ghosh et al. [2016] in the SEQ2SEQ models in order to generate topic-based responses. While these models do come up with responses that might belong to one domain, they raise the question of whether it is sufficient for an intelligent agent to generate a single answer per topic or contex"}
{"text":"While liking or upvoting a post on a mobile app is easy to do, replying with a written note is much more difficult, due to both the cognitive load of coming up with a meaningful response as "}
{"text":"well as the mechanics of entering the text. Here we present a novel textual reply generation model that goes beyond the current auto-reply and predictive text entry models by taking into account the content preferences of the user, the idiosyncrasies"}
{"text":"of their conversational style, and even the structure of their social graph. Specifically, we have developed two types of models for personalized user interactions"}
{"text":"a content-based conversation model, which makes use of location together with user information, and a social-graph- based conversation model, which combines content-based conversation models with social graphs."}
{"text":"Yik Yak is a location-based social app, where people can view text and images posted within a five- mile radius. Users talk about a variety of topics on our platform such as sports, politics, entertainment, food, etc. They voice their opinions on these topics in the form of yaks (posts), comments (replies to yaks), and upvotes and downvotes to both yaks and comments."}
{"text":"This user activity results in a flood of events that we then analyze for a variety of purposes, such as categorizing content, building user profiles, and deriving a social graph, to ultimately provide a more personalized and engaging user experience."}
{"text":"As people discuss a variety of topics on our platform, many different opinions are voiced in the form of upvotes, downvotes, and replies (see Fig. 1). However, typing a reply on a phone is not the most convenient experience, "}
{"text":" so we have started experimenting with the ability to provide highly personalized reply suggestions, with the hope that it will improve user experience and increase engagement on a per-yak basis as well as on the app overall."}
{"text":"There has also been various work on conversation models or chatbots using neural generative models such as seq2seq. We briefly describe some of the related work in this section. Chatbots, also called conversational agents or dialog systems, have been studied by a variety of researchers from both academia and industry. We briefly describe the historical work. There are two main classes of conversational models: retrieval-b"}
{"text":"retrieval based models use a repository of predefined responses and some heuristic to choose an appropriate response based on the input and the context, generative models go beyond predefined responses and are able to generate new responses from scratc"}
{"text":"the practical applications of SEQ2SEQ. Similar to other seq2seq models, the Smart reply system is built on a pair of recurrent neural networks, one used to encode the incoming email and one to predict possible responses. "}
{"text":"The encoding network ingests the words of the incoming email one at a time and produces a vector. This vector, which Geoff Hinton calls a thought vector Hinton [2016], captures the gist of what is being said while abstracting from the specific words used."}
{"text":"While these models are fairly easy to train, they have a tendency to produce generic answers for any type of topic or interaction as presented in Li et al. [2016a]. Also, they suffer from the same issues as general recurrent models, namely a vanishing gradient when the length of the sentence is too long"}
{"text":"There has been recent work that incorporates topic Xing et al. [2016] as well as context Ghosh et al. [2016] in the SEQ2SEQ models in order to generate topic-based responses. While these models do come up with responses that might belong to one domain, they raise the question of whether it is sufficient for an intelligent agent to generate a single answer per topic or contex"}